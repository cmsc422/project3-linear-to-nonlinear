{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks\n",
    "\n",
    "At this point in the semester, you have learned about neural networks and how they can be used and to find nonlinear decision boundaries for classification, and how they can be used for regression. In completing this notebook you will become more familiar with some important concepts in machine learning:\n",
    "\n",
    "- __Backpropagation algorithm__\n",
    "    - Implement the forward and backward pass for the neural network\n",
    "- __Batch gradient descent__\n",
    "    - Choose the correct step size for gradient descent\n",
    "    - Understand the role of step size in convergence of the backprop learning algorithm\n",
    "- __Decision boundary geometry__\n",
    "    - Understand how multi-layer perceptrons create nonlinear decision boundaries\n",
    "- __Regularization and generalization__\n",
    "    - Understand the connection between parameter count and dataset size\n",
    "    - Regularize a network so that it can generalize well\n",
    "- __Applications__\n",
    "    - Train your own neural network on digits data, or a dataset of your choice\n",
    "    - Evaluate the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import util\n",
    "import runClassifier\n",
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "import neuralnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisy, linearly inseparable data\n",
    "\n",
    "For the first part of this project, we will use this dataset. The dataset consists of points randomly sampled from two interleaving half-circles. As you can see, there is significant noise in the data, and the classes are not lienarly separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate a dataset and plot it\n",
    "np.random.seed(0)\n",
    "X, Y = make_moons(200, noise=0.20)\n",
    "plt.scatter(X[:,0], X[:,1], s=40, c=Y, cmap=plt.cm.Spectral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward pass\n",
    "\n",
    "We have provided a partial implemention of a neural network for binary classification. In this project we will work in binary classification, using three-layer networks. Our network will taken in a number of inputs as we define, and the network will produce an output in 2 dimensions. One output is the probability of the positive class, and the other output is the probability of the negative class.\n",
    "\n",
    "__TASK 1:__ Given an input matrix `X` containing our input features, write code to execute the forward pass for each input and return the neural network's outputs for the probability of each class. Your code will be in the method `forward_prop`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will test out your `forward_prop` implementation to make sure it works. You should see `array([[0.56129696, 0.43870304]])` after running this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = neuralnet.ThreeLayerNet()\n",
    "nn.init_weights_task1()\n",
    "nn.forward_prop(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "\n",
    "Now our network can produce an output given an input. Then we can check the predicted output with the target output, and calculate the loss. The error will be back-propagated through the network, so that we can update our weights by batch gradient descent, where the function we are minimizing is the loss function of our network for a given dataset.\n",
    "\n",
    "__TASK 2:__ Now that you know how to compute forward propagation, your next task is to perform backprop. Compute the chage in the weights and biases in the `train` method. You should define `dW1`,`db1`,`dW2`,`db2` so that our network correctly backpropagates and performs an update of the parameters. Check your implementation below. Your loss after 19000 iterations should be around 0.07."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = neuralnet.ThreeLayerNet()\n",
    "iterations,losses = nn.train(X,Y,hdim=3,print_loss=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we can minimize the loss on a dataset of our choice. Let's see how our neural network separated the classes by visualizing the decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.plot_decision_boundary(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our neural network was able to find a decision boundary that successfully separates the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate and convergence\n",
    "\n",
    "Experiment with a few different values for the learning rate `eta`. The cell makes a simple plot of loss vs the number of iterations.\n",
    "\n",
    "__TASK 3:__ Set `eta` to a (nonzero) value for which the neural network does not converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = neuralnet.ThreeLayerNet()\n",
    "iterations,losses = nn.train(X,Y,eta=0, output_dim=2, hdim=2,print_loss=False)\n",
    "plt.plot(iterations,losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TASK 4:__ Set `eta` to a (nonzero) value for which the neural network converges too slowly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = neuralnet.ThreeLayerNet()\n",
    "iterations,losses = nn.train(X,Y,eta=0, output_dim=2, hdim=2,print_loss=False)\n",
    "plt.plot(iterations,losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TASK 5:__ Set `eta` to a (nonzero) value for which the neural network converges at an appropriate rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = neuralnet.ThreeLayerNet()\n",
    "iterations,losses = nn.train(X,Y,eta=0, output_dim=2, hdim=2,print_loss=False)\n",
    "plt.plot(iterations,losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__QUESTION 1:__ For each of the 3 curves, describe how exactly `eta` has affected the shape of the curve, according to gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ANSWER 1:__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision boundary geometry\n",
    "\n",
    "Let's try to classify our dataset with fewer hidden nodes, and see whether we needed 3 units in our hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = neuralnet.ThreeLayerNet()\n",
    "iterations,losses = nn.train(X,Y,hdim=2,print_loss=True)\n",
    "nn.plot_decision_boundary(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__QUESTION 2:__ You should find that this network does not split the data. Our inputs were in 2 dimensions, and our hidden units were also in 2 dimensions. Explain the geometry of the decision boundary, why it has this shape, and why the algorithm does not find a decision boundary that separates the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ANSWER 2:__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of hidden units\n",
    "\n",
    "Let's now get a sense of how varying the size of our hidden layers affects the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = neuralnet.ThreeLayerNet()\n",
    "\n",
    "plt.figure(figsize=(16, 32))\n",
    "hidden_layer_dimensions = [1, 2, 3, 4, 5, 20, 50]\n",
    "for i, hdim in enumerate(hidden_layer_dimensions):\n",
    "    plt.subplot(5, 2, i+1)\n",
    "    plt.title('Hidden Layer size %d' % hdim)\n",
    "    iterations,losses = nn.train(X,Y,hdim=hdim)\n",
    "    nn.plot_decision_boundary(X,Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__QUESTION 3:__ As we increase the number of hidden units, what happens to our ability to generalize? Keep in mind the data-generating distribution that describes our data, from the invocation of `make_moons` above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ANSWER 3:__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications\n",
    "\n",
    "__TASK 6:__ In the cell below, write a routine for training a neural network on `DigitData`. The goal is to train a network that can generalize well. Your network may be any architecture. Plot the loss curve.\n",
    "\n",
    "- If you like, you may choose a different problem, with a dataset of your choice.\n",
    "- You may use any technique to optimize your network.\n",
    "- We don't expect anything fancy, but if you do something impressive, you may earn extra credit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = datasets.DigitData\n",
    "X,Y = data.X,data.Y\n",
    "Y = np.array([0 if y == -1 else 1 for y in Y])\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__QUESTION 4:__ Describe your network. How does it perform?\n",
    "\n",
    "- You can earn some extra credit if you include an error analysis. This of course requires that the problem you choose is difficult for your network to learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ANSWER 4:__ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
